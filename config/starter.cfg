!title LAP Pipeline Template

# LAP Pipeline Template Configuration
# Customize this file for your specific analysis needs

# LAP installation path - CHANGE THIS TO YOUR LAP INSTALLATION
lap_home=/path/to/your/lap/installation

# Run with:
# perl $lap_home/trunk/bin/run.pl --meta /path/to/your/meta/file

# Web UI (if configured):
# https://your-server/~user/lap/
# Enter full path to your meta file

#=======================================================================================================================
# CLASSES
# These define the hierarchical levels at which files are created and commands run
# Each class can have multiple instances defined in the meta file
# Classes form a tree structure with parent-child relationships

class project=Project
class dataset=Dataset parent project
class analysis=Analysis parent dataset
class result=Result parent analysis

#=======================================================================================================================
# DIRECTORIES
# Define the directory structure for your pipeline
# LAP creates these directories automatically when you run --init

sortable mkdir path projects_dir=$unix_out_dir/projects
sortable mkdir path project_dir=$projects_dir/@project class_level project
sortable mkdir path datasets_dir=$project_dir/datasets class_level project
sortable mkdir path dataset_dir=$datasets_dir/@dataset class_level dataset
sortable mkdir path analyses_dir=$dataset_dir/analyses class_level dataset
sortable mkdir path analysis_dir=$analyses_dir/@analysis class_level analysis
sortable mkdir path results_dir=$analysis_dir/results class_level analysis
sortable mkdir path result_dir=$results_dir/@result class_level result

#=======================================================================================================================
# CATEGORIES
# Categories organize files in the web UI

cat project_cat=null disp "Project files" class_level project
cat dataset_cat=null disp "Dataset files" class_level dataset
cat analysis_cat=null disp "Analysis files" class_level analysis
cat result_cat=null disp "Result files" class_level result

#=======================================================================================================================
# FILES
# Define input and output files for your pipeline

# Project level files
path file project_config_file=@project.config.yaml dir project_dir disp "Project Configuration" parent project_cat class_level project

# Dataset level files
path file raw_data_file=@dataset.raw_data.tsv dir dataset_dir disp "Raw Data File" parent dataset_cat class_level dataset
path file dataset_metadata_file=@dataset.metadata.json dir dataset_dir disp "Dataset Metadata" parent dataset_cat class_level dataset

# Analysis level files
path file qc_results_file=@analysis.qc_results.tsv dir analysis_dir disp "Quality Control Results" parent analysis_cat class_level analysis
path file analysis_results_file=@analysis.results.tsv dir analysis_dir disp "Analysis Results" parent analysis_cat class_level analysis
path file analysis_log_file=@analysis.log dir analysis_dir disp "Analysis Log" parent analysis_cat class_level analysis

# Result level files
path file summary_report_file=@result.summary_report.html dir result_dir disp "Summary Report" parent result_cat class_level result
path file plots_file=@result.plots.pdf dir result_dir disp "Analysis Plots" parent result_cat class_level result

#=======================================================================================================================
# COMMANDS
# Define the computational steps of your pipeline
# Each command maps to a stage in your workflow scripts

# Dataset-level commands
local cmd validate_input_cmd=$run_uv_cmd src/workflows/dataset_workflow.py validate \
    --input-file !{input::raw_data_file} \
    --metadata-file !{input::dataset_metadata_file} \
    --output-log !{output::analysis_log_file}; \
    class_level dataset

# Analysis-level commands
local cmd quality_control_cmd=$run_uv_cmd src/workflows/analysis_workflow.py qc \
    --input-file !{input::raw_data_file} \
    --output-file !{output::qc_results_file} \
    --log-file !{output::analysis_log_file}; \
    class_level analysis

local cmd run_analysis_cmd=$run_uv_cmd src/workflows/analysis_workflow.py analyze \
    --input-file !{input::qc_results_file} \
    --output-file !{output::analysis_results_file} \
    --log-file !{output::analysis_log_file}; \
    class_level analysis

# Result-level commands
local cmd generate_report_cmd=$run_uv_cmd src/workflows/result_workflow.py report \
    --input-file !{input::analysis_results_file} \
    --output-html !{output::summary_report_file} \
    --output-plots !{output::plots_file} \
    --project-name !{prop::project}; \
    class_level result

#=======================================================================================================================
# PROPERTIES
# Define scalar properties that can be used throughout the pipeline

prop input_file_path=scalar
prop analysis_type=scalar
prop significance_threshold=scalar

#=======================================================================================================================
# CONFIGURATION
# Include common LAP settings and define custom variables

# LAP core configuration
lap_trunk=$lap_home/trunk
!include $lap_trunk/config/common.cfg

# Project-specific settings
project_bin_dir=src/workflows
project_modules_dir=src/modules
project_root=.

# UV Python environment setup (recommended)
run_uv_cmd=uv run --project $project_root

# Legacy Python environment setup (if not using UV)
# python_env_cmd=source activate my-lap-env
# python_cmd=$python_env_cmd && python

# Override default resource settings if needed
max_jobs=50
default_mem=4000
bsub_opts=-pe smp 1

# Useful utility commands (inherited from common.cfg)
# smart_cut_cmd: Cut/concatenate files
# smart_join_cmd: Join multiple files
# transpose_cmd: Transpose files
# format_columns_cmd: Format column output